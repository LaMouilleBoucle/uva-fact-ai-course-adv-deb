{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import datasets\n",
    "import os\n",
    "from utils import plot_adult_results\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from torch import nn\n",
    "from main import test \n",
    "from model import Predictor, ImagePredictor, Adversary\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt   \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = (os.path.abspath(''))\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"saved_models\")\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results UCI Adult Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Note that in order to obtain the results we report in our paper, we trained 30 different biased predictors (seed 1 - 30) and 30 different debiased predictors (seed 1 - 30)  and averaged the results of those models. <u>In this notebook we will only show the result for a single model trained with the seed set to 15.</u> Results of our report can be reproduced by training with the given seeds following the instructions in the README. \n",
    "\n",
    "The models where trained with the following settings: <br>\n",
    "- Biased\n",
    "> Epochs: 10 <br>\n",
    "> Batch size: 128 <br>\n",
    "> Predictor learning rate: 0.1 <br>\n",
    "\n",
    "- Debiased (Faithful implementation)\n",
    "> Epochs: 30 <br>\n",
    "> Batch size: 128 <br> \n",
    "> Predictor learning rate: 0.01 <br> \n",
    "> Adversary learning rate: 0.001 <br>\n",
    "> Alpha: $\\sqrt t$, where $t$ are the training steps <br> \n",
    "> Decays predictor learning rate every training step $t$ by $\\eta \\leftarrow \\eta \\cdot 1/t$\n",
    "\n",
    "\n",
    "- Debiased (Refined implementation)\n",
    "> Epochs: 15 <br>\n",
    "> Batch size: 128 <br> \n",
    "> Predictor learning rate: 0.001 <br> \n",
    "> Adversary learning rate: 0.001 <br>\n",
    "> Alpha: 0.3 <br> \n",
    "> Exponential decayer gamma: 0.96 (decays every 1000 training steps) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__, __, dataloader_test = datasets.utils.get_dataloaders(batch_size=128, dataset='adult')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filenames of the saved models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_biased_filename = \"pred_debiased_False_adult_seed_15\" \n",
    "pred_debiased_f_filename = \"pred_debiased_True_faithful_adult_seed_15\"\n",
    "pred_debiased_r_filename = \"pred_debiased_True_refined_adult_seed_15\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = next(iter(dataloader_test))[0].shape[1]\n",
    "\n",
    "# Load the biased model \n",
    "predictor_biased = Predictor(input_dim).to(DEVICE)\n",
    "predictor_biased.load_state_dict(torch.load(os.path.join(MODEL_DIR, pred_biased_filename), map_location=DEVICE))\n",
    "predictor_biased.eval();\n",
    "\n",
    "# Load the debiased model (faithful implementation)\n",
    "predictor_debiased_f = Predictor(input_dim).to(DEVICE)\n",
    "predictor_debiased_f.load_state_dict(torch.load(os.path.join(MODEL_DIR, pred_debiased_f_filename), map_location=DEVICE))\n",
    "predictor_debiased_f.eval();\n",
    "\n",
    "# Load the debiased model (refined implementation)\n",
    "predictor_debiased_r = Predictor(input_dim).to(DEVICE)\n",
    "predictor_debiased_r.load_state_dict(torch.load(os.path.join(MODEL_DIR, pred_debiased_r_filename), map_location=DEVICE))\n",
    "predictor_debiased_r.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(confusion_matrix, plot_title=\"\", ax=None):\n",
    "    sns.heatmap(confusion_matrix, annot=True, annot_kws={\"size\": 14}, fmt='g', cbar=False, cmap=\"Blues\", ax = ax)\n",
    "    ax.set_title(plot_title, fontsize=13); \n",
    "    ax.xaxis.set_ticklabels(['Pred 0', 'Pred 1'], fontsize=12); \n",
    "    ax.yaxis.set_ticklabels(['True 0', 'True 1'], fontsize=12);\n",
    "    \n",
    "def plot_confusion_matrices(confusion_matrix_male, confusion_matrix_female, plot_title=\"\"):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(6,2))\n",
    "    plot_confusion_matrix(confusion_matrix_male, plot_title=\"Male\", ax=axs[0])\n",
    "    plot_confusion_matrix(confusion_matrix_female, plot_title=\"Female\", ax=axs[1])\n",
    "    fig.suptitle(plot_title, fontsize=15)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def print_results(accuracy, mutual_info, neg_fpr, pos_fpr, neg_fnr, pos_fnr, model_type=\"\"):\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    print(\"RESULTS %s \\n\"%(model_type.upper()))\n",
    "    print(\"Test accuracy predictor: {:.5f}\".format(accuracy))\n",
    "    print(\"Mutual information I(Z; Y_hat | Y): {:.5f}\\n\".format(mutual_info))\n",
    "    print(\"False Postive Rates (FPR):\")\n",
    "    print(\"      Female: {:.5f} || Male: {:.5f}\".format(neg_fpr, pos_fpr))\n",
    "    print(\"False Negative Rates (FNR):\")\n",
    "    print(\"      Female: {:.5f} || Male: {:.5f}\".format(neg_fnr, pos_fnr))\n",
    "    print()\n",
    "    print(\"Absolute difference FPR between Female vs. Male: {:.5f}\".format(abs(neg_fpr - pos_fpr)))\n",
    "    print(\"Absolute difference FNR between Female vs. Male: {:.5f}\".format(abs(neg_fnr - pos_fnr)))\n",
    "    print(\"-------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results biased predictor\n",
    "accuracy_b, neg_confusion_mat_b, neg_fpr_b, neg_fnr_b, pos_confusion_mat_b, pos_fpr_b, pos_fnr_b, mutual_info_b = test(dataloader_test, \n",
    "                                                                                                           predictor = predictor_biased, \n",
    "                                                                                                           adversary = None, \n",
    "                                                                                                           criterion = nn.BCELoss(), \n",
    "                                                                                                           metric = accuracy_score, \n",
    "                                                                                                           device = DEVICE, \n",
    "                                                                                                           dataset_name = 'adult', \n",
    "                                                                                                           show_logs = False)\n",
    "\n",
    "# Results debiased predictor (faithful implementation)\n",
    "accuracy_dbf, neg_confusion_mat_dbf, neg_fpr_dbf, neg_fnr_dbf, pos_confusion_mat_dbf, pos_fpr_dbf, pos_fnr_dbf, mutual_info_dbf = test(dataloader_test, \n",
    "                                                                                                                           predictor = predictor_debiased_f, \n",
    "                                                                                                                           adversary = None, \n",
    "                                                                                                                           criterion = nn.BCELoss(), \n",
    "                                                                                                                           metric = accuracy_score, \n",
    "                                                                                                                           device = DEVICE, \n",
    "                                                                                                                           dataset_name = 'adult', \n",
    "                                                                                                                           show_logs = False)\n",
    "# Results debiased predictor (refined implementation)\n",
    "accuracy_dbr, neg_confusion_mat_dbr, neg_fpr_dbr, neg_fnr_dbr, pos_confusion_mat_dbr, pos_fpr_dbr, pos_fnr_dbr, mutual_info_dbr = test(dataloader_test, \n",
    "                                                                                                                           predictor = predictor_debiased_r, \n",
    "                                                                                                                           adversary = None, \n",
    "                                                                                                                           criterion = nn.BCELoss(), \n",
    "                                                                                                                           metric = accuracy_score, \n",
    "                                                                                                                           device = DEVICE, \n",
    "                                                                                                                           dataset_name = 'adult', \n",
    "                                                                                                                           show_logs = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrices(pos_confusion_mat_b, neg_confusion_mat_b, plot_title=\"Biased\")\n",
    "plot_confusion_matrices(pos_confusion_mat_dbf, neg_confusion_mat_dbf, plot_title=\"Debiased (Faithful)\")\n",
    "plot_confusion_matrices(pos_confusion_mat_dbr, neg_confusion_mat_dbr, plot_title=\"Debiased (Refined)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(accuracy_b, mutual_info_b, neg_fpr_b, pos_fpr_b, neg_fnr_b, pos_fnr_b, model_type=\"Biased\")\n",
    "print_results(accuracy_dbf, mutual_info_dbf, neg_fpr_dbf, pos_fpr_dbf, neg_fnr_dbf, pos_fnr_dbf, model_type=\"Debiased (Faithful)\")\n",
    "print_results(accuracy_dbr, mutual_info_dbr, neg_fpr_dbr, pos_fpr_dbr, neg_fnr_dbr, pos_fnr_dbr, model_type=\"Debiased (Refined)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots FNR and FPR rates for biased and debiased (refined) setting\n",
    "plot_adult_results([neg_fnr_b], [pos_fnr_b], [neg_fpr_b], [pos_fpr_b], \n",
    "                   [neg_fnr_dbr], [pos_fnr_dbr], [neg_fpr_dbr], [pos_fpr_dbr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results UCI Communities and Crime Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Note that in order to obtain the results we report in our paper, we trained 30 different biased predictors (seed 1 - 30) and 30 different debiased predictors (seed 1 - 30)  and averaged the results of those models. <u>In this notebook we will only show the result for a single model trained with the seed set to 15.</u> Results of our report can be reproduced by training with the given seeds following the instructions in the README. \n",
    "\n",
    "The models where trained with the following settings: <br>\n",
    "- Biased\n",
    "> Epochs: 50 <br>\n",
    "> Batch size: 32 <br>\n",
    "> Predictor learning rate: 0.001 <br>\n",
    "\n",
    "\n",
    "- Debiased\n",
    "> Epochs: 210 <br>\n",
    "> Batch size: 64 <br> \n",
    "> Predictor learning rate: 0.002 <br> \n",
    "> Adversary learning rate: 0.0005 <br>\n",
    "> Alpha: 1.0 <br> \n",
    "> Exponential decayer gamma: 0.96 (decays every 1000 training steps) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader biased \n",
    "__, __, dataloader_test_b = datasets.utils.get_dataloaders(batch_size=32, dataset='crime')\n",
    "\n",
    "# dataloader debiased\n",
    "__, __, dataloader_test_db = datasets.utils.get_dataloaders(batch_size=64, dataset='crime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filenames of the saved models: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_biased_filename = \"pred_debiased_False_crime_seed_15\" \n",
    "pred_debiased_filename = \"pred_debiased_True_crime_seed_15\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = next(iter(dataloader_test_b))[0].shape[1]\n",
    "\n",
    "# Load the biased model \n",
    "predictor_biased = Predictor(input_dim).to(DEVICE)\n",
    "predictor_biased.load_state_dict(torch.load(os.path.join(MODEL_DIR, pred_biased_filename), map_location=DEVICE))\n",
    "predictor_biased.eval();\n",
    "\n",
    "# Load the debiased model\n",
    "predictor_debiased = Predictor(input_dim).to(DEVICE)\n",
    "predictor_debiased.load_state_dict(torch.load(os.path.join(MODEL_DIR, pred_debiased_filename), map_location=DEVICE))\n",
    "predictor_debiased.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results biased predictor\n",
    "MSE_b = test(dataloader_test_b, \n",
    "            predictor = predictor_biased, \n",
    "            adversary = None, \n",
    "            criterion = nn.MSELoss(), \n",
    "            metric = mean_squared_error, \n",
    "            device = DEVICE, \n",
    "            dataset_name = 'crime', \n",
    "            show_logs = False)\n",
    "\n",
    "# Results debiased predictor \n",
    "MSE_db = test(dataloader_test_db, \n",
    "            predictor = predictor_debiased, \n",
    "            adversary = None, \n",
    "            criterion = nn.MSELoss(), \n",
    "            metric = mean_squared_error, \n",
    "            device = DEVICE, \n",
    "            dataset_name = 'crime', \n",
    "            show_logs = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top figure shows the results for without debiasing and the bottom figure shows the results for with debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Biased predictor mean squared error (MSE): {:.5f}\".format(MSE_b))\n",
    "print(\"Debiased predictor mean squared error (MSE): {:.5f}\".format(MSE_db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results UTKFace Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### !! THIS TEXT NEEDS TO BE UPDATED !! \n",
    "###### Note that in order to obtain the results we report in our paper, we trained .... different biased predictors (INSERT SEEDS HERE) and 30 different debiased predictors (INSERT SEEDS HERE)  and averaged the results of those models. <u>In this notebook we will only show the result for a single model trained with the seed set to 1.</u> Results of our report can easily be reproduced by training with the given seeds following the instructions in the README. \n",
    "\n",
    "40-42\n",
    "\n",
    "The models where trained with the following settings: <br>\n",
    "- Biased\n",
    "> Epochs: 30 <br>\n",
    "> Batch size: 128  <br>\n",
    "> Predictor learning rate: 0.001  <br>\n",
    "\n",
    "\n",
    "- Debiased\n",
    "> Epochs: 30  <br>\n",
    "> Batch size: 128 <br> \n",
    "> Predictor learning rate: 0.001  <br> \n",
    "> Adversary learning rate:  0.001 <br>\n",
    "> Alpha: 0.1 <br> \n",
    "> Exponential decayer gamma: ... (decays every .... training steps) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### INSTRUCTIONS TO DOWNLOAD THE DATA HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 3 images.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(40)\n",
    "torch.manual_seed(40)\n",
    "__, dataloader_test, __ = datasets.utils.get_dataloaders(batch_size=128, dataset='images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filenames of the saved models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_biased_filename = \"pred_debiased_False_images_seed_40\"\n",
    "pred_debiased_filename = \"pred_debiased_True_images_seed_40\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = next(iter(dataloader_test))[0].shape[1]\n",
    "output_dim = next(iter(dataloader_test))[1].shape[1]\n",
    "\n",
    "# Load the biased model \n",
    "predictor_biased = ImagePredictor(input_dim, output_dim).to(DEVICE)\n",
    "predictor_biased.load_state_dict(torch.load(os.path.join(MODEL_DIR, pred_biased_filename), map_location=DEVICE))\n",
    "predictor_biased.eval();\n",
    "\n",
    "# Load the debiased model\n",
    "predictor_debiased = ImagePredictor(input_dim, output_dim).to(DEVICE)\n",
    "predictor_debiased.load_state_dict(torch.load(os.path.join(MODEL_DIR, pred_debiased_filename), map_location=DEVICE))\n",
    "predictor_debiased.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(accuracy, neg_auc, pos_auc, model_type=\"\"):\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    print(\"RESULTS %s \\n\"%(model_type.upper()))\n",
    "    print(\"Test accuracy predictor: {:.5f}\".format(accuracy))\n",
    "    print(\"AUC Female: {:.5f} || AUC Male: {:.5f}\".format(neg_auc, pos_auc))\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results biased predictor\n",
    "accuracy_b, neg_auc_b, pos_auc_b = test(dataloader_test, \n",
    "                   predictor = predictor_biased, \n",
    "                   adversary = None, \n",
    "                   criterion = nn.BCELoss(), \n",
    "                   metric = accuracy_score, \n",
    "                   device = DEVICE, \n",
    "                   dataset_name = 'images', \n",
    "                   show_logs = False)\n",
    "                                                                                                        \n",
    "\n",
    "# Results debiased predictor \n",
    "accuracy_db, neg_auc_db, pos_auc_db = test(dataloader_test, \n",
    "                   predictor = predictor_debiased, \n",
    "                   adversary = None, \n",
    "                   criterion = nn.BCELoss(), \n",
    "                   metric = accuracy_score, \n",
    "                   device = DEVICE, \n",
    "                   dataset_name = 'images', \n",
    "                   show_logs = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------\n",
      "RESULTS BIASED \n",
      "\n",
      "Test accuracy predictor: 0.56823\n",
      "AUC Female: 0.91021 || AUC Male: 0.90190\n",
      "-------------------------------------------------------------------\n",
      "-------------------------------------------------------------------\n",
      "RESULTS DEBIASED \n",
      "\n",
      "Test accuracy predictor: 0.55600\n",
      "AUC Female: 0.90611 || AUC Male: 0.90108\n",
      "-------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print_results(accuracy_b, neg_auc_b, pos_auc_b, model_type=\"Biased\")\n",
    "print_results(accuracy_db, neg_auc_db, pos_auc_db, model_type=\"Debiased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
